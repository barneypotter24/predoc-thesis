% !TeX root = ../../thesis.tex
\chapter{Discussion}
\label{ch:discussion}

\section{HBV phylogeography}

In this thesis, we first illustrated the power of Bayesian phylogenetic inference as a \textit{post hoc} analysis tool.
We performed phylogenetic inference on a three large datasets of contemporary \gls{hbv} sequences from around the world.
To two of these datasets we additionally included several genomes isolated from mummies ranging between 500--4,500 years in age.
Conditioned on the results of this phylogenetic inference, we performed phylogeographic inference to identify historical migration events that may have contributed to the current geographic distribution patterns of \gls{hbv}.

We observed that genotype D was the fastest evolving among the \gls{hbv} genotypes.
Genotype E is the most recently diverged genotype, however both its divergence and evolutionary rate estimates had large 95\% highest posterior density intervals, indicating that these estimates have a relatively high degree of uncertainty and must be cautiously interpreted.
This is probably due to the smaller dataset for genotype E (234 sequences), compared to the dataset sizes for the other genotypes (583 and 764 sequences for A and D, respectively).
Additionally, there is recent evidence that \gls{hbv} has limited temporal signal warranting temporal and evolutionary estimation not reliable, particularly for very long timeframes, with the risk of underestimating when the \gls{mrca} diverged \cite{ross2018paradox}.
To avoid the inherent biases of estimating these measures for viruses that have an ancient time of divergence, we opted for analyzing each genotype separately.
Moreover, the short time frame of these datasets, ranging from 16 to 37 years of sampling, should be less affected by the limited temporal signal, thus making the estimation of evolutionary rate and time to \gls{mrca} more reliable \cite{worobey2020emergence}. %GB: do you have a citation/reference for this statement? perhaps from recent SARS-CoV-2 analyses/publications? %BP: not sure if this is exactly what you had in mind, but it is one of the better discussions of evo rates that I know of in the SARS-CoV-2 literature.
The phylogeographic reconstructions are not affected by the temporal inference, particularly because we conditioned it on a posterior subset of trees.

Rather than employing each specific country in our comprehensive dataset as a different location for our discrete phylogeographic reconstruction, we have opted to perform these analyses on the continent level in an attempt to mitigate sampling bias among the different countries in our dataset.
Unfortunately, to maintain consistent geographic subdivisions across datasets there remains significant heterogeneity in number of sequences between regions for some analyses.
Phylogeographic inference using structured coalescent models \cite{de2015new, muller2018mascot} offers a potential solution to deal with sampling bias, at the expense of much increased computational demands.
Given that generating the empirical tree distributions was already very time-consuming on its own, and that this approach cannot be combined with the use of structured coalescent models, we decided to resort to continent-level analysis rather than employing a range of subsampling strategies \cite{hong2020search}.

\section{LASV phylogenetics}

After demonstrating its utility for retrospective analysis of \gls{hbv}, we presented a novel pipeline that unifies dataset preprocessing, Bayesian phylogenetic inference, and figure generation into one automated tool.
This was then applied to genomes collected during seasonal \gls{lasv} outbreaks to demonstrate its utility in both facilitating a single analysis of an entire outbreak, as well as in automating the repetitive elements of an analysis to make real-time online analysis during an outbreak feasible.

\section{Future directions}

One of the biggest challenges in performing Bayesian phylogenetic inference is the large computational burden of analyses.
Depending on the size and complexity of a dataset---as well as the particular statistical model being used and the hardware on which analyses are run---an analysis of a single dataset can take upwards of a month of runtime.
While this can largely be worked around for retrospective analyses of datasets, it proves a major impediment to using Bayesian phylogenetics to analyze ongoing disease outbreaks because current tools are designed to operate on a single dataset.
The utility of such methods breaks down in such situations that require expedient analyses to inform policy and public health decision making.
Because of runtime constraints, complete analyses can plausibly take longer to run than is actionable during the course of an epidemic.
Additionally, current methods do not accommodate changes to datasets or statistical models, often requiring new analyses to be restarted ``from scratch'' after more information regarding a pathogen is uncovered.
While frequent restarts may be feasible for small datasets or relatively simple models that run in a short amount of time, it quickly becomes unreasonable as dataset size and model complexity grow.

\section{Online Bayesian phylogenetic inference}

We have demonstrated the utility of Bayesian phylogenetic inference as a tool for performing rigorous \textit{post hoc} analyses of viral pathogen outbreaks.
However, much work remains to create a fully functional online \gls{beast} framework.
The online build framework described in this thesis may be extended through three major improvements: viral pathogen database integration, phylogenetic and demographic model extensions, and cloud-based task scheduling.

\subsection{Database integration}

One of the most crucial next steps that we identify moving forward towards an ideal online Bayesian phylogenetic framework is the development of tools to seamlessly integrate data streams with analysis pipelines.
In particular, we suggest the combination of \gls{beast}'s analysis tools with genomic databases whose design is focused around efficient, biologically informed storage of both genetic sequence data as well as relevant metadata.
This integration would considerably mitigate the amount of bespoke preprocessing work that is currently required to initiate phylogenetic analyses.
Such ``full stack" pipelines are currently in existence for maximum likelihood based phylogenetics \cite{hadfield2019nextstrain}, however at this time no such framework exists for large-scale Bayesian phylogenetic analysis.

As our next direction, we will integrate existing online \gls{beast} pipelines with GLUE \cite{singer2018glue}---a database software designed specifically for viral genomic sequence data.
This database stores sequence data---and their associated metadata---in a phylogenetically-informed manner as a series of multiple sequence alignments.
This provides several immediate benefits to the rapid initiation of phylogenetic pipelines from an existing database instance.
Because sequences are stored as alignments according to their phylogenetic relationship, selection of sequences and subsampling becomes much easier, as a database API call replaces the need to perform genetic distance calculations as a preprocessing step.
Additionally, because alignments are preexisting within the database it becomes possible to skip the alignment preprocessing step entirely.
Finally, because the GLUE database system is designed with viral pathogen data storage as a core concept, it already supports their commonly associated metadata (i.e. dates, locations, etc.), thereby reducing the potential for error that can be caused when these metadata need to be inserted into analyses by hand.

\subsection{Data insertion and model updates}

Recent developments in \gls{beast} have begun to address the core functionality necessary for online phylogenetic inference, i.e. augmenting ongoing analyses with newly available sequence data under a commonly selected set of models \cite{gill2020online}.
However, much development is still required to make online analysis possible under all models implemented in \gls{beast}.
Current online \gls{beast} only supports sequential (one-at-a-time) insertion of new sequences however, and other scenarios such as batch insertion and removal of sequences need to be developed.

Our next steps will extend the existing sequence-insertion regimes to support a wide range of new sequence numbers and timings (e.g. a doubling of data following a second season of an epidemic).
Following this, we will begin to increase the number of models that are supported with sequence insertion.
This will require new methods for inferring reasonable starting parameter values for each model, as more complex models often have parameter numbers scale with dataset sizes.
One example of this is the Bayesian skygrid demographic model.
Under this model, time is split into windows, and population sizes are inferred for each window separately.
New sequences may result in the addition of new windows---particularly if they fall well outside of the bounds of previously defined timing windows---necessitating a method whereby reasonable initial estimates for population sizes in the new windows may be proposed.

Finally, once an appropriate suite of phylogenetic models have been implemented in the online \gls{beast} framework we must create functions by which models may be ``switched'' following the insertion of new data.
In particular, we must create methods that ``convert'' parameter values from one model to another.
For example, during the early stages of an outbreak we may parameterize our inference simply---say, as an exponentially growing population under a fixed evolutionary rate.
As the outbreak goes on and the number of sequences available grows, it may become apparent that more sophisticated models are necessary to adequately describe the epidemic---for example transitioning to an uncorrelated relaxed clock model with a skygrid demographic model.
In such a case, in order to prevent starting new inference from a totally naive starting position in parameter space it will be necessary to provide new, strongly informative priors based on the parameter values inferred under the previously used models.
By doing this, we will be able to have analyses update dynamically in real-time along with their associated outbreaks.

\subsection{Convergence detection and scheduling}

The final goal that we identify for the development of online \gls{beast} is methods by which multiple analyses can be scheduled automatically.
Functionally, this will require new methods of detecting when parameter posterior distributions have been explored adequately to terminate an analysis.
Currently, our main tools for determining this take the shape of \gls{ess}s and manual inspection of the state of analyses.
This process requires significant time on the behalf of researchers, and is not able to be automated at all.
Through the development of new tools for assessing the completeness of analyses we will be able to automatically detect when analyses should be terminated, thereby preventing unnecessary computation.
By doing so, computational resources will be freed up for new analyses to begin.
If this is achieved, we will be able to create a fully online \gls{beast} environment that runs continuously on cloud computing resources, making maximum use of both available resources and time so that researchers may spend more time analyzing results rather than fussing with the minutiae currently associated with performing Bayesian phylogenetic analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file,
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
