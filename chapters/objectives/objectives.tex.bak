t% !TeX root = ../../thesis.tex
\chapter{Objectives}\label{ch:objectives}

\section{Viral pathogen analysis}

Viral pathogen outbreaks are a particularly useful study system for Bayesian phylogeneticists because their small genomes and fast evolutionary rate facilitate both tractable computation and a constant stream of constantly evolving genomes.
Additionally, viruses frequently cause human suffering and death, both as endemic diseases (seasonal influenza, hepatitis, etc.) and the agents behind sudden disease epidemics (Zika, Ebola, Lassa).
Indeed, viruses have been responsible for the majority of the most deadly pandemics of the last century (1918 Spanish influenza, 2009 Swine flu, Covid-19).
In this thesis, we present the results of the phylogenetic analyses of two separate viral pathogens: Hepatitis B virus (HBV), and Lassa virus.

% \subsection{Zika Virus}
%
% Zika virus (ZIKV) is the causative agent of Zika fever, a disease spread between humans via \textit{Aedes} mosquito hosts.
% It is endemic in the tropical islands of Oceania, and has most recently attracted global notoriety due to the 2015-2016 Zika epidemic in the Americas.
% Zika virus is closely related to Dengue virus, Yellow Fever virus, and West Nile virus, and it is a member of the virus family \textit{Flaviviridae}.
% Zika virus is a positive-sense single stranded RNA virus with a genome approximately 10 kilobases in length.
% Recently, phylogenetic methods have been used to describe the evolution and geographic spread of ZIKV throughout the Americas, and have proven invaluable in revealing both the number of Zika introductions to individual countries, as well as potential modalities of viral spread between countries.
% We are interested in... something?
% Here we use the tools provided in the Nextstrain software package \cite{nextstrain} to reconstruct hypothesized ancestral genomes that were the ancestor to contemporary Zika virus strains.

\subsection{Hepatitis B Virus}

Hepatitis B virus infects over two billion people worldwide, and puts over 350 million people at risk of cirrhosis and liver cancer\cite{kane1995}.
The virus is classified into eight different genotypes based on genomic sequence divergence.
These genotypes show strong ethnospatial patterns, and are often correlated directly to the region of the world where they are most prominent\cite{schaefer2007}.
Hepatitis B virus consists of two partially overlapping strands of DNA.
The long strand ranges from 3020--3320 bases in length, while the short strand ranges from 1700--2800 nucleotides long, depending on genotype\cite{kay2007_hepatitis_b_virus_genetic_variability}.

We are interested in better understanding the spatiotemporal dynamics that have contributed to the current geographic diversity of HBV genotypes A,D, and E.
Unfortunately, one of the difficulties of analyzing HBV genomic datasets is that the virus generally shows very little temporal signal (figure?).
To remedy this we perform temporal phylogeographic analysis of contemporary HBV genomes with the addition of several genomes isolated from the tissue of mummies \cite{muhlemann, ross}.
The genomes range between 500--4,500 years in age, and
These genomes help provide both some temporal signal to our data, as well as give us some information about the historical locations of different HBV genotypes.

\subsection{Lassa Virus}

Talk to Liana about Lassa references
Fill this in.


\section{Online Bayesian phylodynamics}

One of the biggest challenges in performing Bayesian phylogenetic inference is the large computational footprint of analyses.
Depending on the size and complexity of a dataset---as well as the particular statistical model being used and the hardware on which analyses are run---analyses of a single dataset can take upwards of a month of runtime.
While this can largely be worked around for retrospective analyses of datasets, it proves a major impediment to using Bayesian phylogenetics to analyze ongoing disease outbreaks, as complete analyses can plausibly take longer to run than is actionable during the course of an epidemic.
Additionally, current methods no not accommodate changes to datasets or statistical models, often requiring new analyses to be restarted ``from scratch".
While frequent restarts may be feasible for small datasets or relatively simple models that run in a short amount of time, it quickly becomes unreasonable as dataset size and model complexity grows.

\section{Data preprocessing}

Beyond the runtime complexity of currently available phylogeographic inference tools real time analyses are further impeded by the significant amount of preprocessing that they necessitate before raw sequence data can be analyzed.
This preprocessing generally takes the form of bespoke pipelines that require significant manual work to function properly.
While each individual analysis presents challenges unique to the biology of the pathogen of interest, for many analyses the general scheme of data preprocessing is similar.

The prototypical preprocessing pipeline begins with collection of genomic sequence data.
It is not uncommon for genomic data to come from multiple disparate sources.
Genomic databases (e.g. GISAID, ViPR, GenBank) frequently present data to the user in a variety of formats---presenting a major hurdle towards systematically collating genomes into a single dataset.
Additionally, researchers performing analyses frequently wish to include genomes generated by their own research groups or collaborators.
These genomes will generally not be stored on database servers, preventing them from being available to database APIs that could normally assist in the building of datasets.

Even after full datasets are assembled, they may not be the final set of sequences that will be used for phylogenetic inference.
Frequently, researchers wish to downsample their datasets based on a variety of factors---both assisting with runtime and reducing the risk of introducing sampling bias into the final analyses.
Specific genomes may be deemed inappropriate for analysis based on containing incomplete or highly ambiguous sequences.
Genomes may also be excluded based on genetic distance thresholds or their phylogenetic placement in previous analyses.
In addition to removing specific inappropriate sequences, researchers will frequently downsample randomly (or pseudorandomly) to achieve a desired distribution of genomes through time, space, or some other feature of interest.
Finally, researchers may want to ensure that specific sequences are included in their analyses for a variety of reasons, and thus ensure that they are not removed by downsampling procedures.
When running online analyses, it is often desired that the updated set of new sequences need to be included in the analysis, requiring them to be exempt from downsampling.

Following the generation of a suitable dataset of genomes, there are are still several necessary steps that must take place prior to phylogenetic inference that generally require significant manual work.
An important prerequisite step for all molecular phylogenetic inference is the generation of a multiple sequence alignment of all the input genomes.
Many different alignment tools are available to perform this task (e.g. BWA, MUSCLE, MAFFT), however they are generally highly paramaterized tools with many available options that must be explored to create a suitable alignment.
This step in particular often requires a large amount of manual work; many parameter combinations must be explored and alignments must be inspected manually as they cannot be easily validated automatically.
Addition of new sequences in an online setting---though programatically simple if there is an existing framework---must still be validated manually in most cases, posing an obstacle to fully automated build pipelines.

Once an alignment has been generated, phylogenetic models must be specified; this is often a very complicated task.
Some models can be specified in BEAST using its graphical interface, BEAUti.
Unfortunately this program does not support the full suite of models that BEAST can run at this time, and its use in facilitating online phylogenetic analyses is even more limited.
Indeed, for many features that researchers may wish to use the only method for specifying them is by editing code blocks in a source file manually.
While this process is possible to automate for those with sufficient technical knowledge there is no existing method for first-time users of the BEAST ecosystem to do so.
In addition to inital model specification, it is frequently the case that models need to be tweaked follow some runtime either to be optimized or to fix issues that occur during their execution.
This process is currently performed entirely manually by the user, further impeding automatic phylogenetic analysis.

The final preprocessing step necessary before Bayesian phylogenetic analysis can be performed is the specification of MCMC parameters.
This step generally takes place in concert with model specification, as its exact details vary significantly with different statistical models.
Chainlength---the number of iterations that the program will run---scales nonlinearly with dataset size, dataset complexity, and model complexity; it is often estimated as a best guess by the user and cannot be explicitly calculated.
It is often the case that a particular MCMC chainlength is either insufficient to adequately explore the posterior distribution of all parameters, or it is vastly larger than necessary, resulting in excess computational resource being devoted to an analysis.
Prior distributions for all parameters must be specified prior to analysis, and may need to be updated significantly following the addition of new data in an online setting.
Similarly, operators that modify each parameter during a run are particular to each model parameter and may change dynamically as data is introduced to an online build.
Indeed, operators may also need to be changed if they are found to not work well for a given dataset---some may operate too ``slowly" and not explore state space adequately, while others may lack the power to deviate from local extrema in state space and become ``stuck" for thousands, if not millions, of states.
Only after all of these steps have been completed can a user begin to perform the actual phylogenetic inference that interests them.

\section{Thesis objectives}

In this thesis, we first illustrate the power of Bayesian phylogenetic inference as a \textit{post hoc} analysis tool.
We perform phylogenetic inference on a three large datasets of contemporary Hepatitis B virus sequences from around the world.
To two of these datasets we additionally include several genomes isolated from mummies ranging between 500--4,500 years in age.
Conditioned on the results of this phylogenetic inference, we perform phylogeographic inference to identify historical migration events that may have contributed to the current geographic distribution patterns of HBV.

After demonstrating its utility for retrospective analysis, we present a novel pipeline that unifies dataset preprocessing, Bayesian phylogenetic inference, and figure generation into one automated tool.
This is then applied to genomes collected during seasonal Nigerian Lassa fever outbreaks to demonstrate its utility in both facilitating a single analysis of an entire outbreak, as well as in automating the repetitive elements of an analysis to make real-time online analysis during an outbreak feasible.

Finally, we present a framework by which this process may be extended in the future.
Specifically, we propose a methodology by which our pipeline may interact directly with existing genomic database tools to provide a turnkey database-to-analysis pipeline that is easily used and modified by any user, regardless of their familiarity with the existing phylegenetic analysis ecosystem.
We further describe some of the future work necessary to make this system robust to more phylogenetic models, and able to be run from start to finish without user intervention on cloud compute resources so that they are accessible to all researchers, regardless of access to physical compute resources.
These improvements together constitute an ecosystem in which full online Bayesian phylogenetic analyses may be performed without exposing the user to the back-end operations, increasing both useability and interpretability.

% \section{Convergence detection}
%
% The final issue that presents itself as online Bayesian phylogenetic analysis pipelines are run in an increasingly automated manner is that of how to detect when an analysis has run sufficiently to produce results---that is, to determine of the desired posterior distribution has been adequately explored and sampled.
% Let's have a little discussion about:
% \begin{itemize}
%   \item ESS detection
%   \item Convergence estimation
%   \item scheduling
% \end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file,
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
